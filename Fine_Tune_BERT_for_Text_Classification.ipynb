{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPpO0c29cxkp",
        "outputId": "7fd0c4fb-a74d-4f43-c8d8-9c069c7886f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EK2GZCGczVs",
        "outputId": "ce56268c-8a95-42d8-c00f-60b82da46f52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "zB4YS0AUdbzr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Dataset"
      ],
      "metadata": {
        "id": "oa2-_vVadbi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path =\"/content/drive/MyDrive/Data/spamdata.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "A4wPdg3LdkrT",
        "outputId": "ea6f94f8-f5ba-48b8-a01e-426cf9a4a104"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9f0751d-e4e4-4183-b1ab-bddc14d8b23c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9f0751d-e4e4-4183-b1ab-bddc14d8b23c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a9f0751d-e4e4-4183-b1ab-bddc14d8b23c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a9f0751d-e4e4-4183-b1ab-bddc14d8b23c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-02c275e6-0d77-418a-a967-01c6f23de236\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-02c275e6-0d77-418a-a967-01c6f23de236')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-02c275e6-0d77-418a-a967-01c6f23de236 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"Did u download the fring app?\",\n          \"Pass dis to all ur contacts n see wat u get! Red;i'm in luv wid u. Blue;u put a smile on my face. Purple;u r realy hot. Pink;u r so swt. Orange;i thnk i lyk u. Green;i realy wana go out wid u. Yelow;i wnt u bck. Black;i'm jealous of u. Brown;i miss you Nw plz giv me one color\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "#check class distribution\n",
        "df['label'].value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axS7sLPSeYSA",
        "outputId": "d40aeff4-5cb4-4dfc-a2e2-66001cb2c5f6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    0.865937\n",
              "1    0.134063\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split dataset into train, validation and test sets"
      ],
      "metadata": {
        "id": "D8A3--TUeHUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'],\n",
        "                                                                    random_state=31,\n",
        "                                                                    test_size=0.3,\n",
        "                                                                    stratify=df['label'])\n",
        "\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
        "                                                              random_state=31,\n",
        "                                                              test_size=0.5,\n",
        "                                                              stratify=temp_labels)"
      ],
      "metadata": {
        "id": "A-I30TW8eFwx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import BERT Model and Tokenizer"
      ],
      "metadata": {
        "id": "i2aE14ncessQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bert pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "#Tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "AKTkZz4jewwe"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenization"
      ],
      "metadata": {
        "id": "XKvhDixQfNc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get length of all messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ihAEH1SKfPls",
        "outputId": "193529fb-9512-4c1e-be0d-0e566289dfc9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set max sequence length\n",
        "max_seq_len = 25"
      ],
      "metadata": {
        "id": "bAGDNzK8fc3E"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids = False\n",
        ")\n",
        "\n",
        "#tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids = False\n",
        ")\n",
        "\n",
        "#tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TK7s9ngfiLG",
        "outputId": "a6c6caf6-a15d-4b11-be83-3cbe6ba255f4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert integer sequences to tensors for train, validation, test set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "metadata": {
        "id": "dTjnhiesgijW"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataLoaders"
      ],
      "metadata": {
        "id": "yNRrPWkBhAT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#Batch size\n",
        "batch_size = 32\n",
        "\n",
        "#wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "#dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "cCjo42mbg-gy"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Freeze pretrained parameters"
      ],
      "metadata": {
        "id": "nOE8Ws7nutAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "IgdW25JfhtTJ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Add new layers for model"
      ],
      "metadata": {
        "id": "3xC04e95hzqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Architect(nn.Module):\n",
        "  def __init__(self, bert):\n",
        "    super(BERT_Architect, self).__init__()\n",
        "\n",
        "    self.bert = bert\n",
        "\n",
        "    #dropout layer\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    # relu activation function\n",
        "    self.relu =  nn.ReLU()\n",
        "\n",
        "    # dense layer 1\n",
        "    self.fc1 = nn.Linear(768,512)\n",
        "\n",
        "    # dense layer 2 (Output layer)\n",
        "    self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "    #softmax activation function\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "  #define the forward pass\n",
        "  def forward(self, sent_id, mask):\n",
        "\n",
        "    #pass the inputs to the model\n",
        "    _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
        "\n",
        "    x = self.fc1(cls_hs)\n",
        "\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    # output layer\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    # apply softmax activation\n",
        "    x = self.softmax(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "rMQezK0Gjr5M"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add new layers to pre-trained BERT\n",
        "model = BERT_Architect(bert)\n",
        "\n",
        "#push the model to GPU\n",
        "print(model)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyhc0Cy7kP6Z",
        "outputId": "1b375545-6ea3-498f-a243-66c3ab468f1c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT_Architect(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (relu): ReLU()\n",
            "  (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer from hugging face transformer\n",
        "from transformers import AdamW\n",
        "\n",
        "#define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "metadata": {
        "id": "yk59fpdqlBo0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca0839f-2b8c-4ad4-e915-bfb86a073baf"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find class weight\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_labels),\n",
        "    y=train_labels\n",
        ")\n",
        "\n",
        "print(class_wts)"
      ],
      "metadata": {
        "id": "Hof8OC3plLw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a3a55d-ef9b-4c4f-82d6-f46f48078615"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.57743559 3.72848948]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights)\n",
        "\n",
        "# number of training epochs\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "QqknFE95qmLj"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-tuning BERT"
      ],
      "metadata": {
        "id": "j8MeNvfvlS0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "\n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "\n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients\n",
        "    model.zero_grad()\n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "LTdb2i__lZDW"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "\n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "\n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "\n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "\n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader)\n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "gprwfU1ImlKO"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Free Frozen All Parameters"
      ],
      "metadata": {
        "id": "xPQCmMNcs1QQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "HvWx1WKSs3Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Model"
      ],
      "metadata": {
        "id": "uCpTyYqwmq-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "\n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "\n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "id": "OwkvoH5nmqR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save model**"
      ],
      "metadata": {
        "id": "5VBEqmAsm90W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "mPFIAuVJm_23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "5BiJ_1cSnBlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "id": "vZNO4IhsnDzv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
